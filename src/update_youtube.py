import os
import pandas as pd

from lib.mytube import download_subtitle, get_video_list
from lib.myai import get_summary

# === è¨­å®šé »é“ç¶²å€ ===
channel_url = 'https://www.youtube.com/@Drberg/videos'

# === è¨­å®š CSV æª”æ¡ˆåç¨± ===
csv_file = 'video_list.csv'

script_dir = os.path.dirname(os.path.abspath(__file__)) + '/../scripts/'
summary_dir = os.path.dirname(os.path.abspath(__file__)) + '/../summary/'

def update_list():
    # === yt-dlp åƒæ•¸è¨­å®š ===
    videos = get_video_list(channel_url)

    # === å»ºç«‹æ–°å½±ç‰‡çš„DataFrame ===
    new_videos = []
    for video in reversed(videos):
        video_id = video.get('id')
        new_videos.append({
            'id': video_id,
            'title': video.get('title'),
            'url': f"https://www.youtube.com/watch?v={video_id}",
            'date': video.get('upload_date', 'unknown')
        })

    new_df = pd.DataFrame(new_videos)

    # === è‹¥æ—¥æœŸå­˜åœ¨ï¼Œè½‰æ›æ ¼å¼ ===
    def format_date(date):
        return f"{date[:4]}-{date[4:6]}-{date[6:]}" if date != 'unknown' else date

    new_df['date'] = new_df['date'].apply(format_date)

    # === è®€å–ç¾æœ‰çš„CSVæª”æ¡ˆ ===
    try:
        existing_df = pd.read_csv(csv_file)
        last_idx = existing_df['idx'].max()
    except FileNotFoundError:
        existing_df = pd.DataFrame(columns=['idx', 'id', 'title', 'url', 'date'])
        last_idx = 0

    # === æ¯”è¼ƒä¸¦åˆä½µæ–°èˆŠè³‡æ–™ ===
    new_videos_mask = ~new_df['id'].isin(existing_df['id'])
    if new_videos_mask.any():
        # å–å¾—æ–°å½±ç‰‡ä¸¦åè½‰é †åº
        new_videos_df = new_df[new_videos_mask].iloc[::-1].copy()
        # ç‚ºæ–°å½±ç‰‡åŠ å…¥éå¢çš„ idx
        new_videos_count = len(new_videos_df)
        new_videos_df['idx'] = range(last_idx + 1, last_idx + new_videos_count + 1)
        
        # åˆä½µæ–°èˆŠè³‡æ–™
        combined_df = pd.concat([existing_df, new_videos_df], ignore_index=True)
        
        # å„²å­˜æ›´æ–°å¾Œçš„è³‡æ–™
        combined_df.to_csv(csv_file, index=False)
        print(f"ğŸ“Œ å·²æ›´æ–° {new_videos_mask.sum()} éƒ¨æ–°å½±ç‰‡")
        return combined_df
    else:
        print("ğŸ“Œ æ²’æœ‰æ–°å½±ç‰‡")
        return existing_df

def download_script(df):
    # ç¢ºä¿ script_dir å­˜åœ¨
    os.makedirs(script_dir, exist_ok=True)
    
    # è¨ˆæ•¸å™¨
    download_count = 0
    max_downloads = 3
    
    # å„ªå…ˆå­—å¹•èªè¨€åˆ—è¡¨
    preferred_langs = ['en']
    
    # å¾æœ€å¾Œä¸€ç­†å¾€å‰è™•ç†
    for idx in reversed(df.index):
        if download_count >= max_downloads:
            print(f"ğŸ“Œ å·²é”åˆ°æœ€å¤§ä¸‹è¼‰æ•¸é‡ ({max_downloads})")
            break
            
        video_id = df.loc[idx, 'id']
        script_file = f"{script_dir}/{video_id}.txt"
        
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(script_file):
            print(f"ğŸ“Œ è·³éå·²å­˜åœ¨çš„å­—å¹•ï¼š{video_id}")
            continue
            
        print(f"ğŸ“Œ ä¸‹è¼‰å­—å¹•ä¸­ï¼š{video_id}")
        download_count += 1
        
        try:
            subtitle_text, formatted_date = download_subtitle(video_id, preferred_langs)

            # å­˜æˆå­—å¹•æª”
            if subtitle_text:
                with open(script_file, 'w', encoding='utf-8') as f:
                    f.write(subtitle_text)
                print(f"âœ… å­—å¹•å·²å„²å­˜ç‚ºï¼š{script_file}") 
            
                # æ›´æ–° DataFrame ä¸­çš„ upload_date
                if formatted_date:
                    df.loc[idx, 'date'] = formatted_date
                    # æ›´æ–° CSV æª”æ¡ˆ
                    df.to_csv(csv_file, index=False)
                                                   
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•— {video_id}: {str(e)}")
            continue

        summerize_script()
    
    return df

def summerize_script():
    # ç¢ºä¿ summary ç›®éŒ„å­˜åœ¨
    os.makedirs(summary_dir, exist_ok=True)
    
    # å–å¾—æ‰€æœ‰ scripts ç›®éŒ„ä¸‹çš„ txt æª”æ¡ˆ
    script_files = [f for f in os.listdir(script_dir) if f.endswith('.txt')]
    
    # è¨ˆæ•¸å™¨
    processed_count = 0
    
    for script_file in script_files:
        # å–å¾—æª”åï¼ˆä¸å«å‰¯æª”åï¼‰
        fname = os.path.splitext(script_file)[0]
        
        # æª¢æŸ¥å°æ‡‰çš„ summary æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        summary_file = f"{summary_dir}{fname}.md"
        script_path = f"{script_dir}{script_file}"
        
        if not os.path.exists(summary_file):
            print(f"ğŸ“ è™•ç†æ‘˜è¦ä¸­ï¼š{fname}")
            
            try:
                # è®€å–å­—å¹•æª”æ¡ˆ
                with open(script_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç”¢ç”Ÿæ‘˜è¦
                summary_text = get_summary(content)
                
                # å¯«å…¥æ‘˜è¦æª”æ¡ˆ
                with open(summary_file, 'w', encoding='utf-8') as f:
                    f.write(summary_text)
                
                print(f"âœ… æ‘˜è¦å·²å„²å­˜ï¼š{summary_file}")
                processed_count += 1
                
            except Exception as e:
                print(f"âŒ æ‘˜è¦ç”¢ç”Ÿå¤±æ•— {fname}: {str(e)}")
                continue
    
    if processed_count > 0:
        print(f"ğŸ“Œ å®Œæˆ {processed_count} å€‹æª”æ¡ˆçš„æ‘˜è¦")
    else:
        print("ğŸ“Œ æ²’æœ‰éœ€è¦è™•ç†çš„æª”æ¡ˆ")

def create_doc():
    pass

def email_notify():
    pass

if __name__ == '__main__':
    df = update_list()
    download_script(df)
    # summerize_script()
    create_doc()
    email_notify()
