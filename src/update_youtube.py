import os
import pandas as pd
import random

from lib.mytube import download_subtitle, get_video_list
from lib.myai import get_summary

# === è¨­å®šé »é“ç¶²å€ ===
channel_url = 'https://www.youtube.com/@Drberg/videos'

# === è¨­å®š CSV æª”æ¡ˆåç¨± ===

base_dir = os.path.dirname(os.path.abspath(__file__)) + '/../'
script_dir = os.path.join(base_dir, 'scripts/')
summary_dir = os.path.join(base_dir, 'summary/')  
docs_dir = os.path.join(base_dir, 'docs/')
readme_file = os.path.join(base_dir, 'README.md')  
csv_file =  os.path.join(base_dir, 'src/video_list.csv')

def update_list():
    # === yt-dlp åƒæ•¸è¨­å®š ===
    videos = get_video_list(channel_url)

    # === å»ºç«‹æ–°å½±ç‰‡çš„DataFrame ===
    new_videos = []
    for video in reversed(videos):
        video_id = video.get('id')
        new_videos.append({
            'id': video_id,
            'title': video.get('title'),
            'url': f"https://www.youtube.com/watch?v={video_id}",
            'date': video.get('upload_date', 'unknown')
        })

    new_df = pd.DataFrame(new_videos)

    # === è‹¥æ—¥æœŸå­˜åœ¨ï¼Œè½‰æ›æ ¼å¼ ===
    def format_date(date):
        return f"{date[:4]}-{date[4:6]}-{date[6:]}" if date != 'unknown' else date

    new_df['date'] = new_df['date'].apply(format_date)

    # === è®€å–ç¾æœ‰çš„CSVæª”æ¡ˆ ===
    try:
        existing_df = pd.read_csv(csv_file)
        last_idx = existing_df['idx'].max()
    except FileNotFoundError:
        existing_df = pd.DataFrame(columns=['idx', 'id', 'title', 'url', 'date'])
        last_idx = 0

    # === æ¯”è¼ƒä¸¦åˆä½µæ–°èˆŠè³‡æ–™ ===
    new_videos_mask = ~new_df['id'].isin(existing_df['id'])
    if new_videos_mask.any():
        # å–å¾—æ–°å½±ç‰‡ä¸¦åè½‰é †åº
        new_videos_df = new_df[new_videos_mask].iloc[::-1].copy()
        # ç‚ºæ–°å½±ç‰‡åŠ å…¥éå¢çš„ idx
        new_videos_count = len(new_videos_df)
        new_videos_df['idx'] = range(last_idx + 1, last_idx + new_videos_count + 1)
        
        # åˆä½µæ–°èˆŠè³‡æ–™
        combined_df = pd.concat([existing_df, new_videos_df], ignore_index=True)
        
        # å„²å­˜æ›´æ–°å¾Œçš„è³‡æ–™
        combined_df.to_csv(csv_file, index=False)
        print(f"ğŸ“Œ å·²æ›´æ–° {new_videos_mask.sum()} éƒ¨æ–°å½±ç‰‡")
        return combined_df
    else:
        print("ğŸ“Œ æ²’æœ‰æ–°å½±ç‰‡")
        return existing_df

def download_script(df):
    # ç¢ºä¿ script_dir å­˜åœ¨
    os.makedirs(script_dir, exist_ok=True)
    
    # è®€å–é»‘åå–®
    black_list_file = os.path.join(base_dir, 'src/black_list.csv')
    try:
        black_df = pd.read_csv(black_list_file)
    except FileNotFoundError:
        black_df = pd.DataFrame(columns=['idx', 'id', 'url'])
    
    # è¨ˆæ•¸å™¨
    download_count = 0
    max_downloads = 10
    
    # å„ªå…ˆå­—å¹•èªè¨€åˆ—è¡¨
    preferred_langs = ['en']
    
    # å¾æœ€å¾Œä¸€ç­†å¾€å‰è™•ç†
    lst = df.index
    if random.random() < 0.5:
        lst = reversed(lst)
    for idx in lst:
        if download_count >= max_downloads:
            print(f"ğŸ“Œ å·²é”åˆ°æœ€å¤§ä¸‹è¼‰æ•¸é‡ ({max_downloads})")
            break
            
        video_id = df.loc[idx, 'id']
        
        # æª¢æŸ¥æ˜¯å¦åœ¨é»‘åå–®ä¸­
        if video_id in black_df['id'].values:
            print(f"âš ï¸ è·³éé»‘åå–®å½±ç‰‡ï¼š{idx}:{video_id}")
            continue
        
        script_file = f"{script_dir}/{video_id}.txt"
        
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(script_file):
            print(f"ğŸ“Œ è·³éå·²å­˜åœ¨çš„å­—å¹•ï¼š{idx}:{video_id}")
            continue
            
        print(f"ğŸ“Œ ä¸‹è¼‰å­—å¹•ä¸­ï¼š{idx}:{video_id}")
        
        try:
            subtitle_text, formatted_date = download_subtitle(video_id, preferred_langs)

            # å­˜æˆå­—å¹•æª”
            if subtitle_text:
                with open(script_file, 'w', encoding='utf-8') as f:
                    f.write(subtitle_text)
                print(f"âœ… å­—å¹•å·²å„²å­˜ç‚ºï¼š{script_file}") 
                download_count += 1
            
                # æ›´æ–° DataFrame ä¸­çš„ upload_date
                if formatted_date:
                    df.loc[idx, 'date'] = formatted_date
                    # æ›´æ–° CSV æª”æ¡ˆ
                    df.to_csv(csv_file, index=False)
                                                   
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•— {idx}:{video_id}: {str(e)}")
            # åŠ å…¥é»‘åå–®
            new_black = pd.DataFrame([{
                'idx': idx,
                'id': video_id,
                'url': f"https://www.youtube.com/watch?v={video_id}"
            }])
            black_df = pd.concat([black_df, new_black], ignore_index=True)
            # å„²å­˜é»‘åå–®
            black_df.to_csv(black_list_file, index=False)
            print(f"âš ï¸ å·²åŠ å…¥é»‘åå–®ï¼š{idx}:{video_id}")
            continue
   
    return df

def summerize_script():
    # ç¢ºä¿ summary ç›®éŒ„å­˜åœ¨
    os.makedirs(summary_dir, exist_ok=True)
    
    # å–å¾—æ‰€æœ‰ scripts ç›®éŒ„ä¸‹çš„ txt æª”æ¡ˆ
    script_files = [f for f in os.listdir(script_dir) if f.endswith('.txt')]
    
    # è¨ˆæ•¸å™¨
    processed_count = 0
    
    for script_file in script_files:
        # å–å¾—æª”åï¼ˆä¸å«å‰¯æª”åï¼‰
        fname = os.path.splitext(script_file)[0]
        
        # æª¢æŸ¥å°æ‡‰çš„ summary æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        summary_file = f"{summary_dir}{fname}.md"
        script_path = f"{script_dir}{script_file}"
        
        if not os.path.exists(summary_file):
            print(f"ğŸ“ è™•ç†æ‘˜è¦ä¸­ï¼š{fname}")
            
            try:
                # è®€å–å­—å¹•æª”æ¡ˆ
                with open(script_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç”¢ç”Ÿæ‘˜è¦
                summary_text = get_summary(content)
                
                # å¯«å…¥æ‘˜è¦æª”æ¡ˆ
                with open(summary_file, 'w', encoding='utf-8') as f:
                    f.write(summary_text)
                
                print(f"âœ… æ‘˜è¦å·²å„²å­˜ï¼š{summary_file}")
                processed_count += 1
                
            except Exception as e:
                print(f"âŒ æ‘˜è¦ç”¢ç”Ÿå¤±æ•— {fname}: {str(e)}")
                continue
    
    if processed_count > 0:
        print(f"ğŸ“Œ å®Œæˆ {processed_count} å€‹æª”æ¡ˆçš„æ‘˜è¦")
    else:
        print("ğŸ“Œ æ²’æœ‰éœ€è¦è™•ç†çš„æª”æ¡ˆ")

def make_doc(filename: str, video_list: list):
    """
    å°‡å½±ç‰‡æ¸…å–®è£½ä½œæˆæ–‡ä»¶
    Args:
        filename (str): è¼¸å‡ºçš„æ–‡ä»¶åç¨±
        video_list (list): å½±ç‰‡è³‡æ–™åˆ—è¡¨
    """

    # æª”æ¡ˆæ¨¡æ¿
    details_template = """<details>
<summary>{idx}. {date}{title}</summary><br>

<a href="https://www.youtube.com/watch?v={id}" target="_blank">
    <img src="https://img.youtube.com/vi/{id}/maxresdefault.jpg" 
        _target="blank" alt="[Youtube]" width="200">
</a>

{summary_file}
</details>

"""

    # åœ–ç‰‡æ¨¡æ¿
    image_template = """
"""

    try:
        # ç¢ºä¿ç›®æ¨™ç›®éŒ„å­˜åœ¨
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        # ä¾ idx ç”±å¤§åˆ°å°æ’åº
        sorted_videos = sorted(video_list, key=lambda x: x['idx'], reverse=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            for video in sorted_videos:
                # è™•ç†æ—¥æœŸæ ¼å¼
                id = video['id']
                date_str = f"[{video['date']}] " if video['date'] != 'unknown' else ""
                
                # æª¢æŸ¥æ˜¯å¦æœ‰æ‘˜è¦æª”æ¡ˆ
                summary_path = f"{summary_dir}{id}.md"
                summary_content = ""
                if os.path.exists(summary_path):
                    with open(summary_path, 'r', encoding='utf-8') as sf:
                        summary_content = sf.read()
                
                # å¡«å…¥æ¨¡æ¿
                content = details_template.format(
                    idx=video['idx'],
                    date=date_str,
                    title=video['title'],
                    id=id,
                    summary_file=summary_content
                )
                
                f.write(content)
                
    except Exception as e:
        print(f"âŒ è£½ä½œæ–‡ä»¶å¤±æ•— {filename}: {str(e)}")

def create_readme_doc(max_idx, latest_date):
    content = f"""# Dr. Eric Berg DC ({latest_date})

---

"""
    # åå‘è¨ˆç®—ç¯„åœ
    start_batch = (max_idx - 1) // 100  # æœ€å¤§çš„æ‰¹æ¬¡ç·¨è™Ÿ
    
    # å¾å¤§åˆ°å°éæ­·
    for i in range(start_batch, -1, -1):
        start_idx = i * 100 + 1
        end_idx = min((i + 1) * 100, max_idx)
        content += f"- [{start_idx:04d}~{end_idx:04d}](docs/{i:02d}-index.md)\n"

    content += "\n---\n"

    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(content)


def create_doc(df):
    """
    å¾ DataFrame ä¸­åˆ†æ‰¹å–å‡ºå½±ç‰‡è³‡æ–™ï¼Œä¸¦å‘¼å« make_doc è£½ä½œæ–‡ä»¶
    æ¯æ‰¹æ¬¡è™•ç† idx ç¯„åœå…§çš„æ‰€æœ‰è³‡æ–™ï¼ˆå¦‚1-100å…§çš„æ‰€æœ‰å­˜åœ¨çš„idxï¼‰
    æª”åæ ¼å¼ç‚º 01-index.md, 02-index.md, ...
    """
    try:
        # å–å¾—æœ€å¤§çš„ idx
        max_idx = df['idx'].max()
        batch_size = 100
        
        # è¨ˆç®—éœ€è¦ç”¢ç”Ÿå¹¾å€‹æª”æ¡ˆ
        num_batches = (max_idx + batch_size - 1) // batch_size  # å‘ä¸Šå–æ•´
        
        # è™•ç†æ¯ä¸€æ‰¹æ¬¡
        for batch_num in range(num_batches):
            # è¨ˆç®—ç•¶å‰æ‰¹æ¬¡çš„ idx ç¯„åœ
            start_idx = batch_num * batch_size + 1
            end_idx = min((batch_num + 1) * batch_size, max_idx)
            
            # å–å‡ºç¬¦åˆ idx ç¯„åœçš„è³‡æ–™
            batch_df = df[df['idx'].between(start_idx, end_idx)]
            
            # å¦‚æœé€™å€‹ç¯„åœæœ‰è³‡æ–™æ‰è™•ç†
            if not batch_df.empty:
                # ç”¢ç”Ÿæª”å (01-index.md, 02-index.md, ...)
                filename = f"{docs_dir}/{batch_num:02d}-index.md"
                
                # å°‡ DataFrame è½‰æ›æˆå­—å…¸åˆ—è¡¨
                video_list = batch_df.to_dict('records')
                
                print(f"ğŸ“ è™•ç†æ–‡ä»¶ï¼š{filename} (idx: {start_idx}-{end_idx}, å¯¦éš›ç­†æ•¸: {len(video_list)})")
                
                # å‘¼å« make_doc è£½ä½œæ–‡ä»¶
                make_doc(filename, video_list)
                
                print(f"âœ… å®Œæˆæ–‡ä»¶ï¼š{filename}")
        
        print(f"ğŸ“Œ ç¸½å…±ç”¢ç”Ÿäº† {num_batches} å€‹æ–‡ä»¶")

        # å–å¾—æœ€æ–°æ—¥æœŸ
        latest_date = df['date'].iloc[-1]
        create_readme_doc(max_idx, latest_date)
        
    except Exception as e:
        print(f"âŒ è™•ç†æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")

def email_notify():
    pass

if __name__ == '__main__':
    df = update_list()
    download_script(df)
    summerize_script()
    create_doc(df)
    email_notify()
